{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zainabudp/US-Traffic-Accidents/blob/main/traffic_accidents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "031f2ddb-0c76-48af-ab5a-0ffa24375415",
      "metadata": {
        "id": "031f2ddb-0c76-48af-ab5a-0ffa24375415"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aedd768-44f6-42c5-bf3c-79bc669735af",
      "metadata": {
        "id": "7aedd768-44f6-42c5-bf3c-79bc669735af"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(r\"D:\\US_Accidents_March23.csv\\US_Accidents_March23.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8406d003-c66d-4d29-9533-f2a78cbc80f6",
      "metadata": {
        "collapsed": true,
        "id": "8406d003-c66d-4d29-9533-f2a78cbc80f6"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7cf7ce-7de5-4ad2-b971-b578041a40c7",
      "metadata": {
        "collapsed": true,
        "id": "cc7cf7ce-7de5-4ad2-b971-b578041a40c7"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69476897-23f0-4b65-9fbc-18aaf9c0aa8c",
      "metadata": {
        "collapsed": true,
        "id": "69476897-23f0-4b65-9fbc-18aaf9c0aa8c"
      },
      "outputs": [],
      "source": [
        "df['Severity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60ffbea-5768-46b9-8fcd-f6c7b2123068",
      "metadata": {
        "id": "b60ffbea-5768-46b9-8fcd-f6c7b2123068"
      },
      "outputs": [],
      "source": [
        "# Convert 'Start_Time' column to datetime format with error handling\n",
        "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
        "\n",
        "# Display rows with parsing errors\n",
        "rows_with_errors = df[df['Start_Time'].isna()]\n",
        "print(\"Rows with parsing errors:\")\n",
        "print(rows_with_errors)\n",
        "\n",
        "# Continue with the rest of the code to filter the dataset\n",
        "filtered_dfs = []\n",
        "\n",
        "# Iterate over each year from 2016 to 2023\n",
        "for year in range(2016, 2024):\n",
        "    # Filter the dataset for the current year and select 10,000 rows\n",
        "    filtered_df = df[df['Start_Time'].dt.year == year].head(10000)\n",
        "    # Append the filtered dataset to the list\n",
        "    filtered_dfs.append(filtered_df)\n",
        "\n",
        "# Concatenate the filtered datasets into a single dataframe\n",
        "final_df = pd.concat(filtered_dfs, ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the final dataframe\n",
        "final_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f30191-b39b-4789-b518-6c8f5622e3c1",
      "metadata": {
        "id": "d6f30191-b39b-4789-b518-6c8f5622e3c1"
      },
      "outputs": [],
      "source": [
        "final_df['Severity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "187a5da9-267a-486d-b28b-c01dae1ad10f",
      "metadata": {
        "id": "187a5da9-267a-486d-b28b-c01dae1ad10f"
      },
      "outputs": [],
      "source": [
        "# Define a function to map severity levels\n",
        "def map_severity(severity):\n",
        "    if severity in [1, 2]:\n",
        "        return 'Low'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "# Apply the function to create a new column 'Binary_Severity'\n",
        "final_df['Binary_Severity'] = final_df['Severity'].map(map_severity)\n",
        "\n",
        "# Check the value counts of the new column\n",
        "print(final_df['Binary_Severity'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f51160-d920-4259-aa7f-1cc279fe351e",
      "metadata": {
        "id": "93f51160-d920-4259-aa7f-1cc279fe351e"
      },
      "outputs": [],
      "source": [
        "missing_percentage = (final_df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "# Get the columns with missing values exceeding 10%\n",
        "columns_to_drop = missing_percentage[missing_percentage > 10].index\n",
        "\n",
        "# Drop the columns from the dataframe\n",
        "final_df = final_df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Print the remaining columns\n",
        "print(\"Columns after removing those with missing values more than 10%:\")\n",
        "print(final_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71d5ccfb-7404-44b7-87c8-e6787d797ca0",
      "metadata": {
        "id": "71d5ccfb-7404-44b7-87c8-e6787d797ca0"
      },
      "outputs": [],
      "source": [
        "df=final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40ce4d7-d21d-49c5-9c90-a5a494e8c4c1",
      "metadata": {
        "id": "e40ce4d7-d21d-49c5-9c90-a5a494e8c4c1"
      },
      "outputs": [],
      "source": [
        "# Columns to remove\n",
        "columns_to_remove = ['ID', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Description', 'Timezone']\n",
        "\n",
        "# Remove specified columns\n",
        "filtered_df = df.drop(columns=columns_to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9cd6c0-39aa-41e6-9e27-4026d010fcc7",
      "metadata": {
        "id": "0c9cd6c0-39aa-41e6-9e27-4026d010fcc7"
      },
      "outputs": [],
      "source": [
        "filtered_df['County'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "960c143e-f5c9-42ac-bda6-423f61576a78",
      "metadata": {
        "id": "960c143e-f5c9-42ac-bda6-423f61576a78"
      },
      "outputs": [],
      "source": [
        "# Columns to remove\n",
        "columns_to_remove = ['Street', 'Zipcode', 'Country','Airport_Code', 'Weather_Timestamp']\n",
        "\n",
        "# Remove specified columns\n",
        "filtered_df = filtered_df.drop(columns=columns_to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6565758f-c34f-4978-ab18-863d81daab4d",
      "metadata": {
        "id": "6565758f-c34f-4978-ab18-863d81daab4d"
      },
      "outputs": [],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91191fe-737f-4d54-a3ad-3fbf681c5e5e",
      "metadata": {
        "id": "a91191fe-737f-4d54-a3ad-3fbf681c5e5e"
      },
      "outputs": [],
      "source": [
        "# Count occurrences of each unique value in 'City', 'County', and 'State'\n",
        "city_counts = filtered_df['City'].value_counts()\n",
        "county_counts = filtered_df['County'].value_counts()\n",
        "state_counts = filtered_df['State'].value_counts()\n",
        "\n",
        "# Identify values with less than 100 occurrences\n",
        "city_to_remove = city_counts[city_counts < 100].index\n",
        "county_to_remove = county_counts[county_counts < 100].index\n",
        "state_to_remove = state_counts[state_counts < 100].index\n",
        "\n",
        "# Filter out instances with values to remove\n",
        "filtered_df = filtered_df[~filtered_df['City'].isin(city_to_remove)]\n",
        "filtered_df = filtered_df[~filtered_df['County'].isin(county_to_remove)]\n",
        "filtered_df = filtered_df[~filtered_df['State'].isin(state_to_remove)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58939961-06a1-4719-b048-72df5e61c1b4",
      "metadata": {
        "id": "58939961-06a1-4719-b048-72df5e61c1b4"
      },
      "outputs": [],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2623195-58a1-400f-8e8d-270f98cc6761",
      "metadata": {
        "id": "c2623195-58a1-400f-8e8d-270f98cc6761"
      },
      "outputs": [],
      "source": [
        "# Convert 'Start_Time' and 'End_Time' to datetime\n",
        "filtered_df['Start_Time'] = pd.to_datetime(filtered_df['Start_Time'])\n",
        "filtered_df['End_Time'] = pd.to_datetime(filtered_df['End_Time'])\n",
        "\n",
        "# Extract hour and year from 'Start_Time' and 'End_Time'\n",
        "filtered_df['Start_Hour'] = filtered_df['Start_Time'].dt.hour\n",
        "filtered_df['Start_Year'] = filtered_df['Start_Time'].dt.year\n",
        "filtered_df['End_Hour'] = filtered_df['End_Time'].dt.hour\n",
        "filtered_df['End_Year'] = filtered_df['End_Time'].dt.year\n",
        "# Remove original columns\n",
        "filtered_df.drop(columns=['Start_Time', 'End_Time'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49de97ad-5de5-462e-95ed-470fd9c3e1a6",
      "metadata": {
        "id": "49de97ad-5de5-462e-95ed-470fd9c3e1a6"
      },
      "outputs": [],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5108891-5f21-415a-9cfe-bba2a3a70479",
      "metadata": {
        "id": "d5108891-5f21-415a-9cfe-bba2a3a70479"
      },
      "outputs": [],
      "source": [
        "df_viz=filtered_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f141115a-ca4d-4b62-880c-36448f13e1ff",
      "metadata": {
        "id": "f141115a-ca4d-4b62-880c-36448f13e1ff"
      },
      "outputs": [],
      "source": [
        "severity_counts = df_viz['Binary_Severity'].value_counts()\n",
        "\n",
        "# Plotting the bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "severity_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Number of Severity Samples')\n",
        "plt.xlabel('Severity')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid lines for better visualization\n",
        "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e8f0a8-6fe0-4779-8fc6-ae20f67e41ad",
      "metadata": {
        "id": "03e8f0a8-6fe0-4779-8fc6-ae20f67e41ad"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Convert categorical variables to numeric using LabelEncoder\n",
        "for col in filtered_df.columns:\n",
        "    if filtered_df[col].dtype == 'object':\n",
        "        filtered_df[col] = label_encoder.fit_transform(filtered_df[col])\n",
        "\n",
        "# Check the converted DataFrame\n",
        "filtered_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c12a1c-0fcb-40a2-a875-029f7de8115d",
      "metadata": {
        "id": "08c12a1c-0fcb-40a2-a875-029f7de8115d"
      },
      "outputs": [],
      "source": [
        "filtered_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2a9a0f-ae15-45a4-83c2-dfef11bf50a1",
      "metadata": {
        "id": "4c2a9a0f-ae15-45a4-83c2-dfef11bf50a1"
      },
      "outputs": [],
      "source": [
        "filtered_df.drop(['Severity'],inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387fa8fe-1298-495b-9739-b6f513d9ab76",
      "metadata": {
        "id": "387fa8fe-1298-495b-9739-b6f513d9ab76"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = filtered_df.corr()\n",
        "\n",
        "# Extract the top 10 variables correlated with 'Severity' (excluding 'Severity' itself)\n",
        "top_10_variables = correlation_matrix['Binary_Severity'].abs().nlargest(11)[1:]\n",
        "\n",
        "# Select only the top 10 variables from the correlation matrix\n",
        "correlation_matrix_top_10 = correlation_matrix.loc[top_10_variables.index, 'Binary_Severity']\n",
        "\n",
        "# Plot the correlation of the top 10 variables with 'Severity' using a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix_top_10.to_frame(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation with Severity - Top 10 Variables')\n",
        "plt.xlabel('Variable')\n",
        "plt.ylabel('Severity')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b873732-4f84-40b0-bd83-377cf6b8e815",
      "metadata": {
        "id": "6b873732-4f84-40b0-bd83-377cf6b8e815"
      },
      "outputs": [],
      "source": [
        "filtered_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464db0d8-1588-4939-b013-40c9a9a83b45",
      "metadata": {
        "id": "464db0d8-1588-4939-b013-40c9a9a83b45"
      },
      "outputs": [],
      "source": [
        "filtered_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a571f73-d25b-49c9-9aa8-8dee999c968d",
      "metadata": {
        "id": "4a571f73-d25b-49c9-9aa8-8dee999c968d"
      },
      "outputs": [],
      "source": [
        "# Import SimpleImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Define imputer strategies based on data types\n",
        "imputer_strategies = {\n",
        "    'float64': 'median',\n",
        "    'bool': 'most_frequent',\n",
        "    'int32': 'most_frequent',\n",
        "    'int64': 'most_frequent'\n",
        "}\n",
        "\n",
        "# Initialize SimpleImputer\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=None)\n",
        "\n",
        "# Iterate through columns and impute missing values\n",
        "for col in filtered_df.columns:\n",
        "    dtype = filtered_df[col].dtype\n",
        "    if col != 'Binary_Severity' and filtered_df[col].isnull().sum() > 0:  # Skip Severity column and columns without missing values\n",
        "        imputer.strategy = imputer_strategies[str(dtype)]\n",
        "        filtered_df[col] = imputer.fit_transform(filtered_df[[col]])\n",
        "\n",
        "# Verify if missing values are imputed\n",
        "filtered_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a6fa22-abf2-4cb3-b829-ddf77716ad06",
      "metadata": {
        "id": "37a6fa22-abf2-4cb3-b829-ddf77716ad06"
      },
      "outputs": [],
      "source": [
        "filtered_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e06a58-ecfa-4b74-895c-770f526784e1",
      "metadata": {
        "id": "f7e06a58-ecfa-4b74-895c-770f526784e1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Convert categorical variables to numeric using LabelEncoder\n",
        "for col in filtered_df.columns:\n",
        "    if filtered_df[col].dtype == 'bool':\n",
        "        filtered_df[col] = label_encoder.fit_transform(filtered_df[col])\n",
        "\n",
        "# Check the converted DataFrame\n",
        "filtered_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d48360c-8bf1-4e1f-9971-72b2a80f30f2",
      "metadata": {
        "id": "4d48360c-8bf1-4e1f-9971-72b2a80f30f2"
      },
      "source": [
        "## Default model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b98d18-7537-4b84-a57d-3f5fe4c19b6e",
      "metadata": {
        "id": "f4b98d18-7537-4b84-a57d-3f5fe4c19b6e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45e16da-6a93-4bff-a897-658031c52fec",
      "metadata": {
        "id": "a45e16da-6a93-4bff-a897-658031c52fec"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X = filtered_df.drop(columns=['Binary_Severity'])\n",
        "y = filtered_df['Binary_Severity']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Normalize the input variables\n",
        "scaler = StandardScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625ba752-f7df-489f-a044-aef87481c74f",
      "metadata": {
        "id": "625ba752-f7df-489f-a044-aef87481c74f"
      },
      "outputs": [],
      "source": [
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'XGBoost': XGBClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'MLP': MLPClassifier(random_state=42, max_iter=1000)\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    start_time = time.time()  # Start time for training\n",
        "    # Train the classifier\n",
        "    clf.fit(X_train_normalized, y_train)\n",
        "    end_time = time.time()  # End time for training\n",
        "    training_time = end_time - start_time  # Calculate training time\n",
        "\n",
        "    # Cross-validation scores\n",
        "    cv_scores = cross_val_score(clf, scaler.transform(X), y, cv=5)\n",
        "    mean_cv_score = np.mean(cv_scores)\n",
        "    # Predict labels\n",
        "    y_pred = clf.predict(X_test_normalized)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Calculate probabilities for MLP\n",
        "    if name == 'MLP':\n",
        "        # Predict class labels\n",
        "        y_pred_labels = clf.predict(X_test_normalized)\n",
        "        # Get the index of the positive class\n",
        "        pos_index = np.where(clf.classes_ == 1)[0][0]\n",
        "        # Manually calculate probabilities\n",
        "        y_pred_prob = clf.predict_proba(X_test_normalized)\n",
        "        y_pred_prob = y_pred_prob[:, pos_index]\n",
        "    else:\n",
        "        # Calculate probabilities for other classifiers\n",
        "        y_pred_prob = clf.predict_proba(X_test_normalized)[:, 1]\n",
        "\n",
        "    # Calculate ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "\n",
        "    # Calculate AUC score\n",
        "    auc_score = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{name} ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"{name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot confusion matrix with imshow\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
        "\n",
        "    # Add color bar\n",
        "    plt.colorbar()\n",
        "\n",
        "    # Set ticks\n",
        "    tick_marks = np.arange(len(np.unique(y_test)))\n",
        "    plt.xticks(tick_marks, np.unique(y_test), rotation=45)\n",
        "    plt.yticks(tick_marks, np.unique(y_test))\n",
        "\n",
        "    # Add annotations\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"green\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'{name} Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f\"{name} Evaluation Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Mean Cross-validation Score:\", mean_cv_score)\n",
        "    print(\"Training Time:\", training_time, \"seconds\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282d111d-d53d-430b-891a-1bc1a0b23620",
      "metadata": {
        "id": "282d111d-d53d-430b-891a-1bc1a0b23620"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a337dfd-2ac2-47c0-893f-4aca3ec7de7c",
      "metadata": {
        "id": "3a337dfd-2ac2-47c0-893f-4aca3ec7de7c"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56454812-fe6c-4d94-bc6c-a87205609674",
      "metadata": {
        "id": "56454812-fe6c-4d94-bc6c-a87205609674"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Select the top 10 features using mutual information\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=10)\n",
        "X_selected = selector.fit_transform(X_train, y_train)\n",
        "\n",
        "# Get selected features indices\n",
        "selected_features_indices = selector.get_support(indices=True)\n",
        "selected_features = X.columns[selected_features_indices]\n",
        "\n",
        "# Print the names of the selected features\n",
        "print(\"Selected Features:\")\n",
        "for feature in selected_features:\n",
        "    print(feature)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599adaad-fc06-4927-bfba-094f4c954b86",
      "metadata": {
        "id": "599adaad-fc06-4927-bfba-094f4c954b86"
      },
      "outputs": [],
      "source": [
        "feature_scores = selector.scores_[selected_features_indices]\n",
        "\n",
        "# Sort the features and scores\n",
        "sorted_indices = np.argsort(feature_scores)[::-1]\n",
        "sorted_features = selected_features[sorted_indices]\n",
        "sorted_scores = feature_scores[sorted_indices]\n",
        "\n",
        "# Plot the top 10 features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(range(len(sorted_features)), sorted_scores, align='center')\n",
        "plt.yticks(range(len(sorted_features)), sorted_features)\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Selected Features')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b9c33a-0ccf-4f8d-8692-594b18f66903",
      "metadata": {
        "id": "d3b9c33a-0ccf-4f8d-8692-594b18f66903"
      },
      "source": [
        "## Model Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae822f1-7695-434e-b816-af0359548119",
      "metadata": {
        "id": "3ae822f1-7695-434e-b816-af0359548119"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Initialize classifiers with default hyperparameters\n",
        "classifiers = {\n",
        "    'XGBoost': XGBClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'MLP': MLPClassifier(random_state=42, max_iter=1000)\n",
        "}\n",
        "\n",
        "# Hyperparameters grid for grid search\n",
        "param_grid = {\n",
        "    'XGBoost': {'n_estimators': [100, 200, 300],\n",
        "                'max_depth': [3, 5, 7],\n",
        "                'learning_rate': [0.01, 0.1, 0.2]},\n",
        "    'Random Forest': {'n_estimators': [100, 200, 300],\n",
        "                      'max_depth': [10, 20],\n",
        "                      'min_samples_split': [2, 5]},\n",
        "    'Gradient Boosting': {'n_estimators': [100, 200, 300],\n",
        "                          'learning_rate': [0.01, 0.1],\n",
        "                          'max_depth': [3, 5]},\n",
        "    'MLP': {'hidden_layer_sizes': [(64, 32, 16, 8), (100,)],\n",
        "            'activation': ['relu', 'tanh'],\n",
        "            'alpha': [0.0001, 0.001],\n",
        "            'learning_rate': ['constant', 'adaptive']}\n",
        "}\n",
        "\n",
        "# Perform grid search and hyperparameter tuning for each classifier\n",
        "tuned_classifiers = {}\n",
        "for name, clf in classifiers.items():\n",
        "    start_time = time.time()  # Start time for training\n",
        "    # Perform grid search\n",
        "    grid_search = GridSearchCV(clf, param_grid[name], cv=5)\n",
        "    grid_search.fit(X_train_normalized, y_train)\n",
        "    end_time = time.time()  # End time for training\n",
        "    training_time = end_time - start_time  # Calculate training time\n",
        "\n",
        "    # Get the best model\n",
        "    best_clf = grid_search.best_estimator_\n",
        "\n",
        "    # Train the best model on the normalized training data\n",
        "    best_clf.fit(X_train_normalized, y_train)\n",
        "\n",
        "    # Store the tuned model and best parameters\n",
        "    tuned_classifiers[name] = (best_clf, grid_search.best_params_, training_time)\n",
        "\n",
        "# Evaluate the tuned models on the normalized testing data\n",
        "for name, (clf, best_params, training_time) in tuned_classifiers.items():\n",
        "    # Predict labels\n",
        "    y_pred = clf.predict(X_test_normalized)\n",
        "\n",
        "    # Print best parameters\n",
        "    print(f\"{name} Best Parameters:\", best_params)\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"{name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(np.unique(y_test)))\n",
        "    plt.xticks(tick_marks, np.unique(y_test), rotation=45)\n",
        "    plt.yticks(tick_marks, np.unique(y_test))\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"green\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'{name} Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot ROC curve\n",
        "    y_pred_prob = clf.predict_proba(X_test_normalized)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{name} ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f\"{name} Evaluation Metrics:\")\n",
        "    print(\"Training Time:\", training_time, \"seconds\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc57e700-0c93-4860-aae9-feb75e0d155d",
      "metadata": {
        "id": "fc57e700-0c93-4860-aae9-feb75e0d155d"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=10)  # Specify the number of principal components1\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'XGBoost': XGBClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'MLP': MLPClassifier(random_state=42, max_iter=1000)\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    start_time = time.time()  # Start time for training\n",
        "    # Train the classifier\n",
        "    clf.fit(X_train_pca, y_train)\n",
        "    end_time = time.time()  # End time for training\n",
        "    training_time = end_time - start_time  # Calculate training time\n",
        "\n",
        "    # Cross-validation scores\n",
        "    cv_scores = cross_val_score(clf, pca.transform(X), y, cv=5)\n",
        "    mean_cv_score = np.mean(cv_scores)\n",
        "    # Predict labels\n",
        "    y_pred = clf.predict(X_test_pca)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Calculate probabilities for MLP\n",
        "    if name == 'MLP':\n",
        "        # Predict class labels\n",
        "        y_pred_labels = clf.predict(X_test_pca)\n",
        "        # Get the index of the positive class\n",
        "        pos_index = np.where(clf.classes_ == 1)[0][0]\n",
        "        # Manually calculate probabilities\n",
        "        y_pred_prob = clf.predict_proba(X_test_pca)\n",
        "        y_pred_prob = y_pred_prob[:, pos_index]\n",
        "    else:\n",
        "        # Calculate probabilities for other classifiers\n",
        "        y_pred_prob = clf.predict_proba(X_test_pca)[:, 1]\n",
        "\n",
        "    # Calculate ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "\n",
        "    # Calculate AUC score\n",
        "    auc_score = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{name} ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"{name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot confusion matrix with imshow\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
        "\n",
        "    # Add color bar\n",
        "    plt.colorbar()\n",
        "\n",
        "    # Set ticks\n",
        "    tick_marks = np.arange(len(np.unique(y_test)))\n",
        "    plt.xticks(tick_marks, np.unique(y_test), rotation=45)\n",
        "    plt.yticks(tick_marks, np.unique(y_test))\n",
        "\n",
        "    # Add annotations\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"green\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'{name} Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f\"{name} Evaluation Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Mean Cross-validation Scores:\", mean_cv_score)\n",
        "    print(\"Training Time:\", training_time, \"seconds\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14f0ee6a-651e-4629-a261-9db596c02534",
      "metadata": {
        "id": "14f0ee6a-651e-4629-a261-9db596c02534"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}